{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from time import strftime, strptime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = '../data/external/'\n",
    "\n",
    "trumpSample = dataDir + 'trump/donaldtrump_1449187200.txt'\n",
    "trumpFull = dataDir + 'trump/donaldtrump_1477699200.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper to read the ndljson's\n",
    "def readNDLJson(f):\n",
    "    with open(f) as data:\n",
    "        jsonList = [json.loads(line) for line in data]\n",
    "    return jsonList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper function to take a string and return a python datetime obj\n",
    "def tweetTime(created_at):\n",
    "    # u'Fri Dec 04 00:00:32 +0000 2015'\n",
    "    stamp = strptime(created_at, \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "    \n",
    "    return stamp\n",
    "\n",
    "t1 = tweetTime('Fri Dec 04 00:00:32 +0000 2015')\n",
    "t2 = tweetTime('Fri Dec 04 00:00:32 +0000 2016')\n",
    "t1 > t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to take a tweet, and conditionally update the dictionairy\n",
    "# It takes a json input, and first checks if it's a API rate limit call\n",
    "# \n",
    "\n",
    "def updateDict(tweet):\n",
    "    \n",
    "    # occasionally we'll get an API call from twitter showing up, pass those\n",
    "    try:\n",
    "        if tweet['limit']:\n",
    "            return\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        # Sanity check\n",
    "        if ((tweet['user']) and (tweet['user']['id_str'])):\n",
    "        \n",
    "            user = tweet['user']\n",
    "            userID = tweet['user']['id_str']\n",
    "\n",
    "            # grab timestamp, convert timestamp\n",
    "            timestamp = tweetTime(tweet['created_at'])\n",
    "\n",
    "            # dictionairy check\n",
    "            if twitterDict.has_key(userID):\n",
    "                # Compare if this tweet is newer than existing data\n",
    "                if (timestamp > twitterDict[userID]['timestamp']):\n",
    "\n",
    "                    # Update friends, followers/ing, statuses\n",
    "                    twitterDict[userID]['following'] = user['friends_count']\n",
    "                    twitterDict[userID]['followed'] = user['followers_count']\n",
    "                    twitterDict[userID]['tweetsAll'] = user['statuses_count']\n",
    "\n",
    "                    #and the timestamp!\n",
    "                    twitterDict[userID]['timestamp'] = timestamp\n",
    "\n",
    "\n",
    "                # either way, count the tweet\n",
    "                twitterDict[userID]['tweetsDay'] = twitterDict[userID]['tweetsDay'] + 1\n",
    "\n",
    "            # doesn't have key, instantiate!\n",
    "            else:           \n",
    "                twitterDict[userID] = {'tweetsDay': 1, 'userID': userID}\n",
    "\n",
    "                # Update friends, followers/ing, statuses\n",
    "                twitterDict[userID]['following'] = user['friends_count']\n",
    "                twitterDict[userID]['followed'] = user['followers_count']\n",
    "                twitterDict[userID]['tweetsAll'] = user['statuses_count']\n",
    "                #and the timestamp!\n",
    "                twitterDict[userID]['timestamp'] = timestamp\n",
    "    except:\n",
    "        #print (tweet)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitterDict = {}\n",
    "def readLine():\n",
    "    global twitterDict\n",
    "    corruptedLines = 0\n",
    "    \n",
    "    with open(trumpFull) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                updateDict(json.loads(line))\n",
    "            except:\n",
    "                corruptedLines += 1\n",
    "    print (corruptedLines)\n",
    "                \n",
    "def readLines(x):\n",
    "    #twitterDict = {}\n",
    "    global twitterDict\n",
    "    with open(trumpSample) as f:\n",
    "        for chunk in f.readlines(x):\n",
    "            for line in chunk:\n",
    "                updateDict(json.loads(line))\n",
    "    print (len(twitterDict.keys()))\n",
    "    return twitterDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "readLine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%timeit -n 3 readLine()\n",
    "#%timeit -n 1 test1 = readLines(1)\n",
    "#%timeit -n 1 test10 = readLines(10)\n",
    "#%timeit -n 1 test100 = readLines(100)\n",
    "#%timeit -n 1 test1000 = readLines(1000)\n",
    "#%timeit -n 1 test10000 = readLines(10000)\n",
    "#%timeit -n 1 test100000 = readLines(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193608"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitterDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "aggTweets = pd.DataFrame.from_dict(twitterDict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggTweets['timestamp'] = aggTweets['timestamp'].apply(lambda x: strftime(\"%Y-%m-%d %H:%M:%S\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggTweets.to_csv('../data/processed/trumpAgg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do\n",
    "\n",
    "1. Compartmentalize the `twitterDict` into function\n",
    "2. Create function writeoutCSV() to write out to `donald/hilary_1XXXXX-agg.csv`\n",
    "3. Write code to take either a path/file and `readFile(f)` and `writeoutCSV(f-agg.csv)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
